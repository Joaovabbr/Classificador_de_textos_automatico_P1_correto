{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: João Victor de Almeida Braga\n",
    "\n",
    "Nome: Gabriel de Sousa Fonseca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joaov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joaov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joaov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import unicodedata \n",
    "import nltk\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\joaov\\OneDrive\\Documentos\\Insper\\2° semestre\\CDados\\projeto1-CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aversão para ler no Kindle está mais cara? Eu ...</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Sapiens: uma breve história da humanidade rea...</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paguei para embrulho de presente, e veio sem e...</td>\n",
       "      <td>PLAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eu esperava mais do livro ... Que final chato ...</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O produto que chegou na minhas mãos veio com p...</td>\n",
       "      <td>ED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  Aversão para ler no Kindle está mais cara? Eu ...   CONT\n",
       "1  \"Sapiens: uma breve história da humanidade rea...   CONT\n",
       "2  Paguei para embrulho de presente, e veio sem e...   PLAT\n",
       "3  Eu esperava mais do livro ... Que final chato ...   CONT\n",
       "4  O produto que chegou na minhas mãos veio com p...     ED"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino_classificados.xlsx')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tentei mas ,não deu. Não gosto de abandonar le...</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Confesso que pelas avaliações eu esperava mais...</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Particularmente não sou de livro de auto ajuda...</td>\n",
       "      <td>CONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peço que verifiquem e reparem este erro, acred...</td>\n",
       "      <td>PLAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não comprem, valor abusivo para e-book, amazon...</td>\n",
       "      <td>PLAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  Tentei mas ,não deu. Não gosto de abandonar le...   CONT\n",
       "1  Confesso que pelas avaliações eu esperava mais...   CONT\n",
       "2  Particularmente não sou de livro de auto ajuda...   CONT\n",
       "3  Peço que verifiquem e reparem este erro, acred...   PLAT\n",
       "4  Não comprem, valor abusivo para e-book, amazon...   PLAT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste_classificado.xlsx')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o que considerou como relevante ou não relevante na classificação dos tweets (Target).\n",
    "\n",
    "Targets:\n",
    "\n",
    "$CONT$ - O target \"CONT\" é usado para classificar comentários que se referem a problemas que devem ser resolvidos pelo autor(relacionados ao conteúdo escrito), exemplo: \"Focado apenas em quem deseja estudar melhor, textos rasos e superficiais, com dicas simples que conseguiríamos em algum post de blog na internet, não precisando necessariamente ter um livro para isso.\"\n",
    "\n",
    "$PLAT$ - O target \"PLAT\" é usado para comentários de responsabilidade da Amazon(problemas de utilização da plataforma, valores e/ou problemas com kindle).\n",
    "\n",
    "$ED$ - O target \"ED\" se refere a reclamações direcionadas a editora do livro(problemas de material, rasgos, amassos em diversos livros, erros de formatação, gráfia e organização do livro).\n",
    "\n",
    "$OUTROS$ - O target \"OUTROS\" se refere a tudo aqui que não pode ser direcionado a nenhum dos 3 agentes citados anteriormente ou à ninguém(explicações do conteúdo do livro, criticas não construtivas e/ou extremamente curtas e/ou não objetivas, reclamações referente a transportadora)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tent',\n",
       " 'nao',\n",
       " 'deu',\n",
       " 'nao',\n",
       " 'gost',\n",
       " 'abandon',\n",
       " 'leitur',\n",
       " 'nao',\n",
       " 'desc',\n",
       " 'enred',\n",
       " 'feit',\n",
       " 'so',\n",
       " 'palavra',\n",
       " 'sex',\n",
       " 'mocinh',\n",
       " 'tao',\n",
       " 'grosseir',\n",
       " 'boc',\n",
       " 'suj',\n",
       " 'sent',\n",
       " 'constrang',\n",
       " 'envergonh',\n",
       " 'quer',\n",
       " 'ter',\n",
       " 'pod',\n",
       " 'entrar',\n",
       " 'livr',\n",
       " 'rs',\n",
       " 'dar',\n",
       " 'umas',\n",
       " 'aul',\n",
       " 'comport',\n",
       " 'educaca',\n",
       " 'coit',\n",
       " 'obs',\n",
       " 'cap',\n",
       " 'engan',\n",
       " 'bonit',\n",
       " 'atrat',\n",
       " 'so',\n",
       " 'serv',\n",
       " 'camufl',\n",
       " 'manual',\n",
       " 'palavro',\n",
       " 'confess',\n",
       " 'avaliaco',\n",
       " 'esper',\n",
       " 'maisna',\n",
       " 'livr',\n",
       " 'nao',\n",
       " 'bom',\n",
       " 'problem',\n",
       " 'semelhanc',\n",
       " 'livr',\n",
       " 'anterior',\n",
       " 'li',\n",
       " 'autoramenin',\n",
       " 'virgemcom',\n",
       " 'hom',\n",
       " 'velhoarrog',\n",
       " 'prepotentemilionarioqu',\n",
       " 'usa',\n",
       " 'mulh',\n",
       " 'nao',\n",
       " 'envolv',\n",
       " 'pass',\n",
       " 'magic',\n",
       " 'apaixon',\n",
       " 'vari',\n",
       " 'moment',\n",
       " 'vi',\n",
       " 'leonprincip',\n",
       " 'vinganc',\n",
       " 'nao',\n",
       " 'engan',\n",
       " 'sent',\n",
       " 'tamb',\n",
       " 'personal',\n",
       " 'irma',\n",
       " 'sao',\n",
       " 'parec',\n",
       " 'princip',\n",
       " 'di',\n",
       " 'castellaniposs',\n",
       " 'engan',\n",
       " 'pois',\n",
       " 'so',\n",
       " 'preludi',\n",
       " 'livr',\n",
       " 'mei',\n",
       " 'romantiz',\n",
       " 'estuproa',\n",
       " 'ver',\n",
       " 'form',\n",
       " 'veladapo',\n",
       " 'autor',\n",
       " 'ato',\n",
       " 'personag',\n",
       " 'principal',\n",
       " 'tal',\n",
       " 'precis',\n",
       " 'amad',\n",
       " 'final',\n",
       " 'por',\n",
       " 'pra',\n",
       " 'mim',\n",
       " 'pesso',\n",
       " 'fal',\n",
       " 'nao',\n",
       " 'outr',\n",
       " 'continuacaracterizas',\n",
       " 'forc',\n",
       " 'afim',\n",
       " 'part',\n",
       " 'moment',\n",
       " 'diss',\n",
       " 'nao',\n",
       " 'nao',\n",
       " 'arqu',\n",
       " 'indeciso',\n",
       " 'egoist',\n",
       " 'friomanipuladorinsensivelgrossoum',\n",
       " 'babac',\n",
       " 'marc',\n",
       " 'maior',\n",
       " 'milagr',\n",
       " 'torn',\n",
       " 'car',\n",
       " 'incrivel',\n",
       " 'maravilh',\n",
       " 'incomod',\n",
       " 'mei',\n",
       " 'oqu',\n",
       " 'acontec',\n",
       " 'outr',\n",
       " 'livr',\n",
       " 'li',\n",
       " 'voc',\n",
       " 'gost',\n",
       " 'histor',\n",
       " 'car',\n",
       " 'nao',\n",
       " 'prest',\n",
       " 'boa',\n",
       " 'bacanaqu',\n",
       " 'nao',\n",
       " 'motiv',\n",
       " 'nenhum',\n",
       " 'pra',\n",
       " 'apaixon',\n",
       " 'assim',\n",
       " 'apaixonaess',\n",
       " 'pra',\n",
       " 'voc',\n",
       " 'aind',\n",
       " 'tal',\n",
       " 'dividaporqu',\n",
       " 'moment',\n",
       " 'nenhum',\n",
       " 'reclam',\n",
       " 'pagament',\n",
       " 'paina',\n",
       " 'precis',\n",
       " 'ameacatip',\n",
       " 'pai',\n",
       " 'vai',\n",
       " 'presosalv',\n",
       " 'paiel',\n",
       " 'livr',\n",
       " 'espontan',\n",
       " 'vontadereclam',\n",
       " 'outr',\n",
       " 'seculom',\n",
       " 'foiparticular',\n",
       " 'nao',\n",
       " 'livr',\n",
       " 'aut',\n",
       " 'ajud',\n",
       " 'por',\n",
       " 'tant',\n",
       " 'ouv',\n",
       " 'fal',\n",
       " 'ness',\n",
       " 'livr',\n",
       " 'acab',\n",
       " 'compr',\n",
       " 'aind',\n",
       " 'bem',\n",
       " 'promoca',\n",
       " 'livr',\n",
       " 'nao',\n",
       " 'nad',\n",
       " 'diferent',\n",
       " 'ache',\n",
       " 'leitur',\n",
       " 'chat',\n",
       " 'sempr',\n",
       " 'tud',\n",
       " 'sab',\n",
       " 'nao',\n",
       " 'pratic',\n",
       " 'maior',\n",
       " 'vez',\n",
       " 'dei',\n",
       " 'duas',\n",
       " 'estrel',\n",
       " 'cap',\n",
       " 'ache',\n",
       " 'melhor',\n",
       " 'part',\n",
       " 'livropec',\n",
       " 'verifiqu',\n",
       " 'rep',\n",
       " 'erro',\n",
       " 'acredit',\n",
       " 'muit',\n",
       " 'outr',\n",
       " 'usuari',\n",
       " 'sent',\n",
       " 'les',\n",
       " 'verifiqu',\n",
       " 'antes',\n",
       " 'assin',\n",
       " 'vi',\n",
       " 'tod',\n",
       " 'seri',\n",
       " 'harry',\n",
       " 'pott',\n",
       " 'disponivel',\n",
       " 'pra',\n",
       " 'kindk',\n",
       " 'unlimited',\n",
       " 'dar',\n",
       " 'continu',\n",
       " 'leitur',\n",
       " 'nao',\n",
       " 'ter',\n",
       " 'injust',\n",
       " 'log',\n",
       " 'solicit',\n",
       " 'repar',\n",
       " 'imediat',\n",
       " 'livr',\n",
       " 'digitalna',\n",
       " 'compr',\n",
       " 'valor',\n",
       " 'abus',\n",
       " 'ebook',\n",
       " 'amazon',\n",
       " 'cobr',\n",
       " 'dobr',\n",
       " 'cobr',\n",
       " 'eua',\n",
       " 'financ',\n",
       " 'criseembor',\n",
       " 'gost',\n",
       " 'livr',\n",
       " 'nao',\n",
       " 'faz',\n",
       " 'sent',\n",
       " 'tamb',\n",
       " 'felip',\n",
       " 'net',\n",
       " 'faz',\n",
       " 'ter',\n",
       " 'visa',\n",
       " 'algu',\n",
       " 'batalh',\n",
       " 'dentr',\n",
       " 'youtub',\n",
       " 'livr',\n",
       " 'felip',\n",
       " 'net',\n",
       " 'trajetor',\n",
       " 'maior',\n",
       " 'booktubers',\n",
       " 'fraquissim',\n",
       " 'nao',\n",
       " 'acrescent',\n",
       " 'nad',\n",
       " 'deseduc',\n",
       " 'crianc',\n",
       " 'adolescent',\n",
       " 'brincadeir',\n",
       " 'tip',\n",
       " 'trep',\n",
       " 'cas',\n",
       " 'pass',\n",
       " 'nao',\n",
       " 'ha',\n",
       " 'criativ',\n",
       " 'sim',\n",
       " 'futil',\n",
       " 'pen',\n",
       " 'ja',\n",
       " 'felip',\n",
       " 'net',\n",
       " 'formador',\n",
       " 'opinia',\n",
       " 'public',\n",
       " 'nao',\n",
       " 'recomendoa',\n",
       " 'contrari',\n",
       " 'primeir',\n",
       " 'livr',\n",
       " 'hom',\n",
       " 'sapiens',\n",
       " 'excelent',\n",
       " 'hom',\n",
       " 'deus',\n",
       " 'porc',\n",
       " 'comec',\n",
       " 'muit',\n",
       " 'repetica',\n",
       " 'primeir',\n",
       " 'segu',\n",
       " 'diz',\n",
       " 'acha',\n",
       " 'vai',\n",
       " 'acontec',\n",
       " 'futur',\n",
       " 'inic',\n",
       " 'looooong',\n",
       " 'exposico',\n",
       " 'argumentaco',\n",
       " 'prov',\n",
       " 'cert',\n",
       " 'autor',\n",
       " 'aproveit',\n",
       " 'popular',\n",
       " 'livr',\n",
       " 'anterior',\n",
       " 'escrev',\n",
       " 'qualqu',\n",
       " 'cois',\n",
       " 'vend',\n",
       " 'facil',\n",
       " 'decepcionantelivr',\n",
       " 'agradavel',\n",
       " 'leitur',\n",
       " 'bastant',\n",
       " 'esclarecedor',\n",
       " 'envolv',\n",
       " 'leitor',\n",
       " 'mostr',\n",
       " 'nao',\n",
       " 'so',\n",
       " 'arte',\n",
       " 'racional',\n",
       " 'assunt',\n",
       " 'autor',\n",
       " 'preocup',\n",
       " 'part',\n",
       " 'psicolog',\n",
       " 'envolv',\n",
       " 'dinheir',\n",
       " 'bom',\n",
       " 'livroum',\n",
       " 'livr',\n",
       " 'falt',\n",
       " 'pagin',\n",
       " 'ex',\n",
       " 'pul',\n",
       " 'pag',\n",
       " 'pra',\n",
       " 'pag',\n",
       " 'present',\n",
       " 'pesso',\n",
       " 'so',\n",
       " 'viu',\n",
       " 'lend',\n",
       " 'part',\n",
       " 'perd',\n",
       " 'praz',\n",
       " 'devolucaolivr',\n",
       " 'linguag',\n",
       " 'rebusc',\n",
       " 'complic',\n",
       " 'pouc',\n",
       " 'entend',\n",
       " 'fal',\n",
       " 'basic',\n",
       " 'fisic',\n",
       " 'esper',\n",
       " 'decepcion',\n",
       " 'poucona',\n",
       " 'gost',\n",
       " 'cap',\n",
       " 'diz',\n",
       " 'conteud',\n",
       " 'livro',\n",
       " 'vergonh',\n",
       " 'nao',\n",
       " 'ter',\n",
       " 'versa',\n",
       " 'portugu',\n",
       " 'decent',\n",
       " 'ler',\n",
       " 'kindl',\n",
       " 'vid',\n",
       " 'informaca',\n",
       " 'problem',\n",
       " 'relat',\n",
       " 'tant',\n",
       " 'anos',\n",
       " 'lancament',\n",
       " 'nao',\n",
       " 'versa',\n",
       " 'confiavelsincer',\n",
       " 'tamb',\n",
       " 'tent',\n",
       " 'entend',\n",
       " 'pod',\n",
       " 'coloc',\n",
       " 'livr',\n",
       " 'digital',\n",
       " 'prec',\n",
       " 'absurd',\n",
       " 'dest',\n",
       " 'compr',\n",
       " 'kindl',\n",
       " 'recent',\n",
       " 'ador',\n",
       " 'ter',\n",
       " 'obra',\n",
       " 'nel',\n",
       " 'prec',\n",
       " 'abus',\n",
       " 'dest',\n",
       " 'nao',\n",
       " 'compr',\n",
       " 'aqu',\n",
       " 'chin',\n",
       " 'so',\n",
       " 'dei',\n",
       " 'estrel',\n",
       " 'porqu',\n",
       " 'nao',\n",
       " 'possivel',\n",
       " 'dar',\n",
       " 'quer',\n",
       " 'rel',\n",
       " 'livr',\n",
       " 'depar',\n",
       " 'prec',\n",
       " 'brincadeir',\n",
       " 'amazon',\n",
       " 'r',\n",
       " 'ebook',\n",
       " 'obra',\n",
       " 'val',\n",
       " 'mil',\n",
       " 'estrel',\n",
       " 'dou',\n",
       " 'estrel',\n",
       " 'amazon',\n",
       " 'virtud',\n",
       " 'prec',\n",
       " 'abusivosincer',\n",
       " 'histor',\n",
       " 'nao',\n",
       " 'cativ',\n",
       " 'ache',\n",
       " 'pouc',\n",
       " 'arrast',\n",
       " 'gracatratas',\n",
       " 'livr',\n",
       " 'superficial',\n",
       " 'limit',\n",
       " 'conjunt',\n",
       " 'simplist',\n",
       " 'receitinh',\n",
       " 'pretens',\n",
       " 'rotul',\n",
       " 'habit',\n",
       " 'tamb',\n",
       " 'nao',\n",
       " 'nad',\n",
       " 'original',\n",
       " 'nenhum',\n",
       " 'fundamentaca',\n",
       " 'cientif',\n",
       " 'questa',\n",
       " 'embor',\n",
       " 'assimilaca',\n",
       " 'facil',\n",
       " 'rap',\n",
       " 'nao',\n",
       " 'exig',\n",
       " 'reflexo',\n",
       " 'nao',\n",
       " 'compens',\n",
       " 'temp',\n",
       " 'vai',\n",
       " 'despend',\n",
       " 'leitur',\n",
       " 'nao',\n",
       " 'recom',\n",
       " 'alfred',\n",
       " 'santann',\n",
       " 'juniorfoc',\n",
       " 'apen',\n",
       " 'desej',\n",
       " 'estud',\n",
       " 'melhor',\n",
       " 'text',\n",
       " 'ras',\n",
       " 'superfic',\n",
       " 'dic',\n",
       " 'simpl',\n",
       " 'conseguiri',\n",
       " 'algum',\n",
       " 'post',\n",
       " 'blog',\n",
       " 'internet',\n",
       " 'nao',\n",
       " 'precis',\n",
       " 'necessari',\n",
       " 'ter',\n",
       " 'livr',\n",
       " 'issopel',\n",
       " 'porc',\n",
       " 'grac',\n",
       " 'car',\n",
       " 'nao',\n",
       " 'dei',\n",
       " 'trabalh',\n",
       " 'ler',\n",
       " 'pois',\n",
       " 'comentari',\n",
       " 'leu',\n",
       " 'critic',\n",
       " 'feit',\n",
       " 'pouc',\n",
       " 'conhec',\n",
       " 'histor',\n",
       " 'perceb',\n",
       " 'tratas',\n",
       " 'deturpaca',\n",
       " 'mesquinh',\n",
       " 'nao',\n",
       " 'conhec',\n",
       " 'histor',\n",
       " 'brasil',\n",
       " 'quer',\n",
       " 'conhecel',\n",
       " 'form',\n",
       " 'minim',\n",
       " 'aconselh',\n",
       " 'escolh',\n",
       " 'algum',\n",
       " 'autor',\n",
       " 'men',\n",
       " 'bisonh',\n",
       " 'quer',\n",
       " 'faz',\n",
       " 'piadinh',\n",
       " 'rod',\n",
       " 'amig',\n",
       " 'gost',\n",
       " 'fal',\n",
       " 'raza',\n",
       " 'pod',\n",
       " 'encontr',\n",
       " 'nest',\n",
       " 'definica',\n",
       " 'repositori',\n",
       " 'besteir',\n",
       " 'men',\n",
       " 'util',\n",
       " 'algum',\n",
       " 'passag',\n",
       " 'bob',\n",
       " 'sirv',\n",
       " 'inspiraca',\n",
       " 'algum',\n",
       " 'piad',\n",
       " 'idiot',\n",
       " 'tol',\n",
       " 'bom',\n",
       " 'proveito',\n",
       " 'livr',\n",
       " 'chat',\n",
       " 'enrol',\n",
       " 'apes',\n",
       " 'cont',\n",
       " 'algum',\n",
       " 'dic',\n",
       " 'pod',\n",
       " 'funcion',\n",
       " 'livr',\n",
       " 'cab',\n",
       " 'perfeit',\n",
       " 'paginasvei',\n",
       " 'amass',\n",
       " 'pontasum',\n",
       " 'pouc',\n",
       " 'desapont',\n",
       " 'acho',\n",
       " 'q',\n",
       " 'mta',\n",
       " 'expectativana',\n",
       " 'consig',\n",
       " 'ler',\n",
       " 'confus',\n",
       " 'sit',\n",
       " 'nao',\n",
       " 'consig',\n",
       " 'contat',\n",
       " 'ningu',\n",
       " 'ajud',\n",
       " 'complic',\n",
       " 'amazon',\n",
       " 'esper',\n",
       " 'consegu',\n",
       " 'ler',\n",
       " 'estornoapresentas',\n",
       " 'livr',\n",
       " 'autoajud',\n",
       " 'voc',\n",
       " 'comec',\n",
       " 'ler',\n",
       " 'vai',\n",
       " 'ver',\n",
       " 'trat',\n",
       " 'livr',\n",
       " 'sobr',\n",
       " 'histor',\n",
       " 'habit',\n",
       " 'assemelhas',\n",
       " 'livr',\n",
       " 'didat',\n",
       " 'faculdad',\n",
       " 'pens',\n",
       " 'objet',\n",
       " 'traz',\n",
       " 'tecnic',\n",
       " 'incorpor',\n",
       " 'determin',\n",
       " 'habit',\n",
       " 'vid',\n",
       " 'livr',\n",
       " 'pod',\n",
       " 'reduz',\n",
       " 'ate',\n",
       " 'nao',\n",
       " 'voc',\n",
       " 'entusiast',\n",
       " 'quer',\n",
       " 'sab',\n",
       " 'primordi',\n",
       " 'assunt',\n",
       " 'nao',\n",
       " 'recomendotext',\n",
       " 'nao',\n",
       " 'academ',\n",
       " 'nenhum',\n",
       " 'embas',\n",
       " 'histor',\n",
       " 'escrit',\n",
       " 'nao',\n",
       " 'histori',\n",
       " 'prec',\n",
       " 'acord',\n",
       " 'baix',\n",
       " 'qualidadeentr',\n",
       " 'enderec',\n",
       " 'sobr',\n",
       " 'ganh',\n",
       " 'livr',\n",
       " 'kindl',\n",
       " 'dia',\n",
       " 'escolh',\n",
       " 'livr',\n",
       " 'imediat',\n",
       " 'faz',\n",
       " 'login',\n",
       " 'valor',\n",
       " 'eh',\n",
       " 'debit',\n",
       " 'carta',\n",
       " 'absurd',\n",
       " 'nao',\n",
       " 'quer',\n",
       " 'compr',\n",
       " 'livr',\n",
       " 'solicit',\n",
       " 'devoluca',\n",
       " 'imediat',\n",
       " 'valorparec',\n",
       " 'trabalh',\n",
       " 'garot',\n",
       " 'escol',\n",
       " 'prim',\n",
       " 'quer',\n",
       " 'impression',\n",
       " 'professor',\n",
       " 'frac',\n",
       " 'mal',\n",
       " 'elabor',\n",
       " 'nao',\n",
       " 'inform',\n",
       " 'nad',\n",
       " 'mostras',\n",
       " 'legu',\n",
       " 'promess',\n",
       " 'titulool',\n",
       " 'frequent',\n",
       " 'tend',\n",
       " 'marc',\n",
       " 'merecid',\n",
       " 'mencion',\n",
       " 'cas',\n",
       " 'sucess',\n",
       " 'vao',\n",
       " 'desd',\n",
       " 'referenc',\n",
       " 'bibliograf',\n",
       " 'tccs',\n",
       " 'ate',\n",
       " 'complex',\n",
       " 'analis',\n",
       " 'model',\n",
       " 'design',\n",
       " 'negoci',\n",
       " 'servic',\n",
       " 'ger',\n",
       " 'encant',\n",
       " 'mei',\n",
       " 'relacion',\n",
       " 'client',\n",
       " 'experienc',\n",
       " 'compartilh',\n",
       " 'espant',\n",
       " 'cas',\n",
       " 'insucess',\n",
       " 'empres',\n",
       " 'fiz',\n",
       " 'ped',\n",
       " 'dest',\n",
       " 'livr',\n",
       " 'it',\n",
       " 'cois',\n",
       " 'outr',\n",
       " 'livr',\n",
       " 'previsa',\n",
       " 'entreg',\n",
       " 'algo',\n",
       " 'torn',\n",
       " 'dias',\n",
       " 'outr',\n",
       " 'livr',\n",
       " 'ped',\n",
       " 'enderec',\n",
       " 'etc',\n",
       " 'etc',\n",
       " 'entreg',\n",
       " 'problem',\n",
       " 'livr',\n",
       " 'it',\n",
       " 'cois',\n",
       " 'transport',\n",
       " 'insist',\n",
       " 'enderec',\n",
       " 'incorret',\n",
       " 'oi',\n",
       " 'mor',\n",
       " 'aqu',\n",
       " 'ped',\n",
       " 'ajud',\n",
       " 'via',\n",
       " 'chat',\n",
       " 'sit',\n",
       " 'receb',\n",
       " 'atend',\n",
       " 'incrivel',\n",
       " 'invers',\n",
       " 'proporcional',\n",
       " 'eficac',\n",
       " 'naquel',\n",
       " 'atend',\n",
       " 'ja',\n",
       " 'hav',\n",
       " 'descrit',\n",
       " 'rot',\n",
       " 'cheg',\n",
       " 'aqu',\n",
       " 'pont',\n",
       " 'referenc',\n",
       " 'mei',\n",
       " 'contat',\n",
       " 'ate',\n",
       " 'disponibiliz',\n",
       " 'busc',\n",
       " 'livr',\n",
       " 'algum',\n",
       " 'lug',\n",
       " 'pois',\n",
       " 'import',\n",
       " 'present',\n",
       " 'pesso',\n",
       " 'especial',\n",
       " 'tal',\n",
       " 'nad',\n",
       " 'inici',\n",
       " 'dezembr',\n",
       " 'envi',\n",
       " 'email',\n",
       " 'ped',\n",
       " 'ajud',\n",
       " 'reiter',\n",
       " 'tud',\n",
       " 'apresent',\n",
       " 'atend',\n",
       " 'via',\n",
       " 'chat',\n",
       " 'dia',\n",
       " 'seguint',\n",
       " 'receb',\n",
       " 'email',\n",
       " 'daquel',\n",
       " 'ctrl',\n",
       " 'c',\n",
       " 'ctrl',\n",
       " 'v',\n",
       " 'amazon',\n",
       " 'desculp',\n",
       " 'pergunt',\n",
       " 'gost',\n",
       " 'reembols',\n",
       " 'pront',\n",
       " 'respond',\n",
       " 'entend',\n",
       " 'm',\n",
       " 'acontec',\n",
       " 'desej',\n",
       " 'precis',\n",
       " 'receb',\n",
       " 'livr',\n",
       " 'nov',\n",
       " 'compartilh',\n",
       " 'rot',\n",
       " 'pont',\n",
       " 'referenc',\n",
       " 'autoriz',\n",
       " 'pass',\n",
       " 'telefon',\n",
       " 'celul',\n",
       " 'quer',\n",
       " 'inclu',\n",
       " 'lig',\n",
       " 'cobr',\n",
       " 'necessari',\n",
       " 'repet',\n",
       " 'altern',\n",
       " 'busc',\n",
       " 'algum',\n",
       " 'lug',\n",
       " 'mor',\n",
       " 'sao',\n",
       " 'paul',\n",
       " 'gent',\n",
       " 'nao',\n",
       " 'algum',\n",
       " 'cidad',\n",
       " 'dificil',\n",
       " 'acess',\n",
       " 'alguns',\n",
       " 'dias',\n",
       " 'pass',\n",
       " 'ness',\n",
       " 'milong',\n",
       " 'enfim',\n",
       " 'dia',\n",
       " 'dias',\n",
       " 'apos',\n",
       " 'realiz',\n",
       " 'ped',\n",
       " 'receb',\n",
       " 'soluca',\n",
       " 'compulsor',\n",
       " 'amazon',\n",
       " 'confirmaca',\n",
       " 'reembols',\n",
       " 'reembols',\n",
       " 'ser',\n",
       " 'credit',\n",
       " 'fatur',\n",
       " 'cas',\n",
       " 'carta',\n",
       " 'credit',\n",
       " 'ate',\n",
       " 'dias',\n",
       " 'ute',\n",
       " 'cont',\n",
       " 'corrent',\n",
       " 'carto',\n",
       " 'debit',\n",
       " 'bolet',\n",
       " 'olho',\n",
       " 'amazonfelip',\n",
       " 'net',\n",
       " 'xing',\n",
       " 'tod',\n",
       " 'youtubers',\n",
       " 'fiz',\n",
       " 'livr',\n",
       " 'conteud',\n",
       " 'hoj',\n",
       " 'capitaliz',\n",
       " 'livr',\n",
       " 'assemelh',\n",
       " 'gib',\n",
       " 'turm',\n",
       " 'monic',\n",
       " 'maurici',\n",
       " 'souz',\n",
       " 'perdoeest',\n",
       " 'saudad',\n",
       " 'tod',\n",
       " 'personagens',\n",
       " 'cont',\n",
       " 'assim',\n",
       " 'teatr',\n",
       " 'perd',\n",
       " 'tod',\n",
       " 'magic',\n",
       " 'histor',\n",
       " 'incrivel',\n",
       " 'frac',\n",
       " 'previsivel',\n",
       " 'personagens',\n",
       " 'nao',\n",
       " 'parec',\n",
       " 'mesm',\n",
       " 'desfech',\n",
       " 'sofrivel',\n",
       " 'aibd',\n",
       " 'apresent',\n",
       " 'dramalha',\n",
       " 'mexicano',\n",
       " 'livr',\n",
       " 'bom',\n",
       " 'edica',\n",
       " 'pessim',\n",
       " 'inclu',\n",
       " 'livr',\n",
       " 'critic',\n",
       " 'coloc',\n",
       " 'introduca',\n",
       " 'revel',\n",
       " 'assassin',\n",
       " 'falh',\n",
       " 'absurd',\n",
       " 'editorana',\n",
       " 'porqu',\n",
       " 'tem',\n",
       " 'relev',\n",
       " 'livr',\n",
       " 'necessari',\n",
       " 'bom',\n",
       " 'pouc',\n",
       " 'bons',\n",
       " 'moment',\n",
       " 'geral',\n",
       " 'sent',\n",
       " 'lend',\n",
       " 'fras',\n",
       " 'caminha',\n",
       " 'text',\n",
       " 'breg',\n",
       " 'facebookdeliri',\n",
       " 'parano',\n",
       " 'pesso',\n",
       " 'idiot',\n",
       " 'livr',\n",
       " 'nao',\n",
       " 'idiot',\n",
       " 'automat',\n",
       " 'idiot',\n",
       " 'autor',\n",
       " 'dev',\n",
       " 'fic',\n",
       " 'dand',\n",
       " 'ris',\n",
       " 'pois',\n",
       " 'tant',\n",
       " 'idiot',\n",
       " 'compr',\n",
       " 'livroacab',\n",
       " 'ver',\n",
       " 'trilog',\n",
       " 'impress',\n",
       " 'amazon',\n",
       " 'send',\n",
       " 'ridicul',\n",
       " 'prec',\n",
       " 'pens',\n",
       " 'seri',\n",
       " 'compr',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[´.,\"!-:?;$''@#$%¨&*()_+=~><;/1234567890]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "\n",
    "def separa_palavras(series):\n",
    "    coment_juntos = ''\n",
    "    for i in series:\n",
    "        coment_juntos += i + ''\n",
    "\n",
    "    coment_juntos = coment_juntos.lower()\n",
    "    \n",
    "    return coment_juntos\n",
    "\n",
    "def limpa_acentos(str):\n",
    "    sem_acentos = unicodedata.normalize(\"NFD\", str)\n",
    "    sem_acentos = sem_acentos.encode(\"ascii\", \"ignore\")\n",
    "    sem_acentos = sem_acentos.decode(\"utf-8\")\n",
    "\n",
    "    return sem_acentos\n",
    "\n",
    "\n",
    "def stop_words(texto): \n",
    "    palavras_limpas = []\n",
    "    texto_separado = word_tokenize(texto, language='portuguese')\n",
    "\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    for x in texto_separado:\n",
    "        if x not in stopwords_pt:\n",
    "            palavras_limpas.append(x)\n",
    "    \n",
    "    return palavras_limpas\n",
    "\n",
    "def simplifica_palavra(list_texto):\n",
    "    list_texto_simples = []\n",
    "    stemmer = SnowballStemmer(\"portuguese\")\n",
    "    for palavra in list_texto:\n",
    "        list_texto_simples.append(stemmer.stem(palavra))\n",
    "\n",
    "    return list_texto_simples\n",
    "\n",
    "\n",
    "simplifica_palavra(stop_words(limpa_acentos(cleanup(separa_palavras(test.Mensagem)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>livr</th>\n",
       "      <td>0.042596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nao</th>\n",
       "      <td>0.035061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autor</th>\n",
       "      <td>0.012456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>histor</th>\n",
       "      <td>0.010610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outr</th>\n",
       "      <td>0.007227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financeir</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suger</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psicolog</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestsell</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "livr       0.042596\n",
       "nao        0.035061\n",
       "autor      0.012456\n",
       "histor     0.010610\n",
       "outr       0.007227\n",
       "...             ...\n",
       "logic      0.000154\n",
       "financeir  0.000154\n",
       "suger      0.000154\n",
       "psicolog   0.000154\n",
       "bestsell   0.000154\n",
       "\n",
       "[2016 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trata_df(df,target):\n",
    "    df_target = df.loc[df.Target == target]\n",
    "    lista_df_limpo = simplifica_palavra(stop_words(limpa_acentos(cleanup(separa_palavras(df_target.Mensagem)))))\n",
    "    abs_df_target = pd.Series(lista_df_limpo).value_counts().to_frame()\n",
    "    rel_df_target = pd.Series(lista_df_limpo).value_counts(True).to_frame()\n",
    "    return [abs_df_target,rel_df_target, lista_df_limpo]\n",
    "\n",
    "\n",
    "trata_df(train,'CONT')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_relativo = trata_df(train,'CONT')[0]\n",
    "cont_absoluto = trata_df(train, 'CONT')[1]\n",
    "palavras_cont = trata_df(train, 'CONT')[2]\n",
    "\n",
    "ed_relativo = trata_df(train,'ED')[0]\n",
    "ed_absoluto = trata_df(train, 'ED')[1]\n",
    "palavras_ed = trata_df(train, 'ED')[2]\n",
    "\n",
    "plat_relativo = trata_df(train,'PLAT')[0]\n",
    "plat_absoluto = trata_df(train, 'PLAT')[1]\n",
    "palavras_plat = trata_df(train, 'PLAT')[2]\n",
    "\n",
    "outros_relativo = trata_df(train,'OUTROS')[0]\n",
    "outros_absoluto = trata_df(train, 'OUTROS')[1]\n",
    "palavras_outros = trata_df(train, 'OUTROS')[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2529"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apaga_repetições(total_palavras):\n",
    "    sem_repetição = []\n",
    "    for x in total_palavras:\n",
    "        if x not in sem_repetição:\n",
    "            sem_repetição.append(x)\n",
    "\n",
    "    return sem_repetição\n",
    "\n",
    "palavras_geral = palavras_cont + palavras_ed + palavras_plat + palavras_outros\n",
    "lista_n_repet = apaga_repetições(palavras_geral)\n",
    "\n",
    "len(lista_n_repet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
